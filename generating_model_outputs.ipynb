{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19101/399081887.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from src.dataset import ProteinDataset\n",
    "from src.utils import train_model, test_model\n",
    "import torch\n",
    "from src.model import ChemicalShiftsPredictor, ChemicalShiftsPredictorAttention\n",
    "from src.utils import packed_padded_collate\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "csv_file = 'data/strict.csv'\n",
    "prott5_file = 'data/embeddings/unfiltered_all_prott5.h5'\n",
    "prott5_res_file = 'data/embeddings/unfiltered_all_prott5_res.h5'\n",
    "prostt5_file = 'data/embeddings/prostt5.h5'\n",
    "esm_file = 'data/embeddings/unfiltered_all_esm2_3b.h5'\n",
    "esm_res_file = 'data/embeddings/unfiltered_all_esm2_3b_res.h5'\n",
    "chemical_shifts_df = pd.read_csv(csv_file)\n",
    "\n",
    "test_ids = []\n",
    "with open(\"pdb_matched/final_test_ids.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        test_ids.append(line.strip())\n",
    "        \n",
    "        \n",
    "chemical_shifts_df = chemical_shifts_df[chemical_shifts_df['ID'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergeyer/mambaforge/envs/prots/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bb2b49d0334447a029d8224df6b9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_column = 'H'\n",
    "\n",
    "scaler = joblib.load(f'scaler_h.joblib')\n",
    "#h_filtered = chemical_shifts_df.dropna(subset=[target_column])\n",
    "chemical_shifts_df[target_column] = scaler.transform(chemical_shifts_df[target_column].values.reshape(-1, 1))\n",
    "\n",
    "test_dataset = ProteinDataset([target_column], chemical_shifts_df, prott5_file, prott5_res_file, prostt5_file, esm_res_file, esm_file)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5\n",
    "patience = 10\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "\n",
    "use_prostt5 = True\n",
    "use_protein_mean = True\n",
    "use_attention = True\n",
    "\n",
    "model = ChemicalShiftsPredictor(use_prostt5=use_prostt5, use_protein_mean=use_protein_mean, use_attention=use_attention)\n",
    "model.load_state_dict(torch.load('Full_1e-4_H.pth'))\n",
    "\n",
    "model = model.cuda()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if use_attention:\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=6, collate_fn=packed_padded_collate)\n",
    "else:\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for inputs in tqdm(test_loader):\n",
    "        amino_acid_prott5_emb, amino_acid_prostt5_emb, amino_acid_esm2_emb, protein_prott5_emb, protein_prostt5_emb_stack, targets = [x.to(device) for x in inputs]\n",
    "        embeddings = [amino_acid_prott5_emb]\n",
    "        if use_prostt5:\n",
    "            embeddings.append(amino_acid_prostt5_emb)\n",
    "        if use_protein_mean:\n",
    "            embeddings.append(protein_prott5_emb)\n",
    "            # if use_prostt5:\n",
    "            #     embeddings.append(protein_prostt5_emb)\n",
    "        embeddings.append(amino_acid_esm2_emb)\n",
    "        concatenated_embeddings = torch.cat(embeddings, dim=1)\n",
    "        if use_attention:\n",
    "            sequence_lengths = protein_prostt5_emb_stack.abs().sum(dim=-1).nonzero()[:, 1].max(dim=-1, keepdim=True)[0] + 1\n",
    "\n",
    "            # Create mask based on actual sequence lengths\n",
    "            max_seq_len = protein_prostt5_emb_stack.size(2)\n",
    "            mask = torch.arange(max_seq_len, device=device)[None, :] < sequence_lengths.to(device)\n",
    "            outputs = model(concatenated_embeddings, protein_prostt5_emb_stack.to(device), mask.to(device))\n",
    "            all_predictions.extend(outputs.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.160605],\n",
       "       [8.013003],\n",
       "       [8.667084],\n",
       "       ...,\n",
       "       [9.202308],\n",
       "       [9.353414],\n",
       "       [8.575436]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(np.array(all_predictions).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447       5.350244\n",
       "448       5.297827\n",
       "449       5.783499\n",
       "450       5.552297\n",
       "451       5.647673\n",
       "            ...   \n",
       "215543    7.764286\n",
       "215544    7.869600\n",
       "215545    7.871858\n",
       "215546    7.893819\n",
       "215547    7.905555\n",
       "Name: H_our, Length: 12892, dtype: float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemical_shifts_df[\"H_our\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemical_shifts_df[\"H_our\"] = scaler.inverse_transform(np.array(all_predictions).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergeyer/mambaforge/envs/prots/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a857dc490a8142808d373f79b965692e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_column = 'N'\n",
    "\n",
    "scaler = joblib.load(f'scaler_n.joblib')\n",
    "#h_filtered = chemical_shifts_df.dropna(subset=[target_column])\n",
    "chemical_shifts_df[target_column] = scaler.transform(chemical_shifts_df[target_column].values.reshape(-1, 1))\n",
    "\n",
    "test_dataset = ProteinDataset([target_column], chemical_shifts_df, prott5_file, prott5_res_file, prostt5_file, esm_res_file, esm_file)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5\n",
    "patience = 10\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "\n",
    "use_prostt5 = True\n",
    "use_protein_mean = True\n",
    "use_attention = True\n",
    "\n",
    "model = ChemicalShiftsPredictor(use_prostt5=use_prostt5, use_protein_mean=use_protein_mean, use_attention=use_attention)\n",
    "model.load_state_dict(torch.load('Full_1e-4_N.pth'))\n",
    "\n",
    "model = model.cuda()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if use_attention:\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=6, collate_fn=packed_padded_collate)\n",
    "else:\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for inputs in tqdm(test_loader):\n",
    "        amino_acid_prott5_emb, amino_acid_prostt5_emb, amino_acid_esm2_emb, protein_prott5_emb, protein_prostt5_emb_stack, targets = [x.to(device) for x in inputs]\n",
    "        embeddings = [amino_acid_prott5_emb]\n",
    "        if use_prostt5:\n",
    "            embeddings.append(amino_acid_prostt5_emb)\n",
    "        if use_protein_mean:\n",
    "            embeddings.append(protein_prott5_emb)\n",
    "            # if use_prostt5:\n",
    "            #     embeddings.append(protein_prostt5_emb)\n",
    "        embeddings.append(amino_acid_esm2_emb)\n",
    "        concatenated_embeddings = torch.cat(embeddings, dim=1)\n",
    "        if use_attention:\n",
    "            sequence_lengths = protein_prostt5_emb_stack.abs().sum(dim=-1).nonzero()[:, 1].max(dim=-1, keepdim=True)[0] + 1\n",
    "\n",
    "            # Create mask based on actual sequence lengths\n",
    "            max_seq_len = protein_prostt5_emb_stack.size(2)\n",
    "            mask = torch.arange(max_seq_len, device=device)[None, :] < sequence_lengths.to(device)\n",
    "            outputs = model(concatenated_embeddings, protein_prostt5_emb_stack.to(device), mask.to(device))\n",
    "            all_predictions.extend(outputs.cpu().detach().numpy())\n",
    "            \n",
    "            \n",
    "chemical_shifts_df[\"N_our\"] = scaler.inverse_transform(np.array(all_predictions).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>entryID</th>\n",
       "      <th>stID</th>\n",
       "      <th>entity_assemID</th>\n",
       "      <th>entityID</th>\n",
       "      <th>seq_index</th>\n",
       "      <th>seq</th>\n",
       "      <th>k</th>\n",
       "      <th>zscores</th>\n",
       "      <th>pscores</th>\n",
       "      <th>C</th>\n",
       "      <th>CA</th>\n",
       "      <th>CB</th>\n",
       "      <th>HA</th>\n",
       "      <th>H</th>\n",
       "      <th>N</th>\n",
       "      <th>HB</th>\n",
       "      <th>N_our</th>\n",
       "      <th>H_our</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>6</td>\n",
       "      <td>30161_1_1_1</td>\n",
       "      <td>30161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.986</td>\n",
       "      <td>55.600</td>\n",
       "      <td>33.138</td>\n",
       "      <td>4.401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.816</td>\n",
       "      <td>1.9350</td>\n",
       "      <td>119.632263</td>\n",
       "      <td>5.350244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>6</td>\n",
       "      <td>30161_1_1_1</td>\n",
       "      <td>30161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>14</td>\n",
       "      <td>11.1609</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>174.316</td>\n",
       "      <td>61.588</td>\n",
       "      <td>38.193</td>\n",
       "      <td>3.830</td>\n",
       "      <td>-0.243453</td>\n",
       "      <td>123.431</td>\n",
       "      <td>1.7160</td>\n",
       "      <td>127.461349</td>\n",
       "      <td>5.297827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>6</td>\n",
       "      <td>30161_1_1_1</td>\n",
       "      <td>30161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "      <td>21</td>\n",
       "      <td>14.1291</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>176.156</td>\n",
       "      <td>57.343</td>\n",
       "      <td>32.755</td>\n",
       "      <td>4.716</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>127.627</td>\n",
       "      <td>1.8845</td>\n",
       "      <td>127.118889</td>\n",
       "      <td>5.783499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>6</td>\n",
       "      <td>30161_1_1_1</td>\n",
       "      <td>30161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>T</td>\n",
       "      <td>21</td>\n",
       "      <td>15.1705</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>173.925</td>\n",
       "      <td>58.964</td>\n",
       "      <td>71.096</td>\n",
       "      <td>5.291</td>\n",
       "      <td>0.513443</td>\n",
       "      <td>110.835</td>\n",
       "      <td>4.3560</td>\n",
       "      <td>117.856674</td>\n",
       "      <td>5.552297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>6</td>\n",
       "      <td>30161_1_1_1</td>\n",
       "      <td>30161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>21</td>\n",
       "      <td>14.7280</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>173.317</td>\n",
       "      <td>59.542</td>\n",
       "      <td>43.057</td>\n",
       "      <td>4.875</td>\n",
       "      <td>0.133551</td>\n",
       "      <td>120.009</td>\n",
       "      <td>1.2950</td>\n",
       "      <td>124.396027</td>\n",
       "      <td>5.647673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215543</th>\n",
       "      <td>1893</td>\n",
       "      <td>36334_1_1_1</td>\n",
       "      <td>36334</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8761</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.665993</td>\n",
       "      <td>7.764286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215544</th>\n",
       "      <td>1893</td>\n",
       "      <td>36334_1_1_1</td>\n",
       "      <td>36334</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3427</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.746872</td>\n",
       "      <td>7.869600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215545</th>\n",
       "      <td>1893</td>\n",
       "      <td>36334_1_1_1</td>\n",
       "      <td>36334</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3427</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.091785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.197594</td>\n",
       "      <td>7.871858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215546</th>\n",
       "      <td>1893</td>\n",
       "      <td>36334_1_1_1</td>\n",
       "      <td>36334</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.341019</td>\n",
       "      <td>7.893819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215547</th>\n",
       "      <td>1893</td>\n",
       "      <td>36334_1_1_1</td>\n",
       "      <td>36334</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.376930</td>\n",
       "      <td>7.905555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12892 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0           ID  entryID  stID  entity_assemID  entityID  \\\n",
       "447              6  30161_1_1_1    30161     1               1         1   \n",
       "448              6  30161_1_1_1    30161     1               1         1   \n",
       "449              6  30161_1_1_1    30161     1               1         1   \n",
       "450              6  30161_1_1_1    30161     1               1         1   \n",
       "451              6  30161_1_1_1    30161     1               1         1   \n",
       "...            ...          ...      ...   ...             ...       ...   \n",
       "215543        1893  36334_1_1_1    36334     1               1         1   \n",
       "215544        1893  36334_1_1_1    36334     1               1         1   \n",
       "215545        1893  36334_1_1_1    36334     1               1         1   \n",
       "215546        1893  36334_1_1_1    36334     1               1         1   \n",
       "215547        1893  36334_1_1_1    36334     1               1         1   \n",
       "\n",
       "        seq_index seq   k  zscores  pscores        C      CA      CB     HA  \\\n",
       "447             1   M   7      NaN      NaN  175.986  55.600  33.138  4.401   \n",
       "448             2   I  14  11.1609   0.0947  174.316  61.588  38.193  3.830   \n",
       "449             3   R  21  14.1291   0.0736  176.156  57.343  32.755  4.716   \n",
       "450             4   T  21  15.1705   0.0332  173.925  58.964  71.096  5.291   \n",
       "451             5   I  21  14.7280   0.0497  173.317  59.542  43.057  4.875   \n",
       "...           ...  ..  ..      ...      ...      ...     ...     ...    ...   \n",
       "215543        106   H   1   3.8761   0.0000      NaN     NaN     NaN    NaN   \n",
       "215544        107   H   2   2.3427   0.4918      NaN     NaN     NaN    NaN   \n",
       "215545        108   H   2   2.3427   0.4918      NaN     NaN  30.053    NaN   \n",
       "215546        109   H   2      NaN      NaN      NaN     NaN     NaN    NaN   \n",
       "215547        110   H   0      NaN      NaN      NaN     NaN     NaN    NaN   \n",
       "\n",
       "               H        N      HB       N_our     H_our  \n",
       "447          NaN  121.816  1.9350  119.632263  5.350244  \n",
       "448    -0.243453  123.431  1.7160  127.461349  5.297827  \n",
       "449     2.210679  127.627  1.8845  127.118889  5.783499  \n",
       "450     0.513443  110.835  4.3560  117.856674  5.552297  \n",
       "451     0.133551  120.009  1.2950  124.396027  5.647673  \n",
       "...          ...      ...     ...         ...       ...  \n",
       "215543       NaN      NaN     NaN  115.665993  7.764286  \n",
       "215544       NaN      NaN     NaN  117.746872  7.869600  \n",
       "215545 -0.091785      NaN     NaN  118.197594  7.871858  \n",
       "215546       NaN      NaN     NaN  118.341019  7.893819  \n",
       "215547       NaN      NaN     NaN  122.376930  7.905555  \n",
       "\n",
       "[12892 rows x 20 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemical_shifts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select N_our, H_our, ID, entryID, seq_index, seq and save to csv\n",
    "df = chemical_shifts_df[['N_our', 'H_our', 'ID', 'entryID', 'seq_index', 'seq']]\n",
    "df.to_csv('data/our_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
